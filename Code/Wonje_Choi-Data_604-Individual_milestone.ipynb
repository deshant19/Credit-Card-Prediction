{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fall 2021: DATA 604\n",
    "\n",
    "Team Project (Individual milestone) \n",
    "\n",
    "Due: Monday, November 22, 2021 (by 22:00 MST)\n",
    "\n",
    "Name: Wonje Choi \n",
    "\n",
    "UCID: 30016397"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector\n",
    "import csv\n",
    "from mysql.connector import errorcode\n",
    "import pandas as pd\n",
    "import sqlalchemy as sq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1. \n",
    "\n",
    "Create connection to the default schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    connection = mysql.connector.connect(user='wonje_choi2', database='wonje_choi2', password='5WSC84ETK', host=\"datasciencedb.ucalgary.ca\")\n",
    "except mysql.connector.Error as err:\n",
    "    if err.errno == errorcode.ER_ACCESS_DENIED_ERROR:\n",
    "        print(\"Wrong Infomation\")\n",
    "        exit()\n",
    "    elif err.errno == errorcode.ER_BAD_DB_ERROR:\n",
    "        print(\"Database does not exist\")\n",
    "        exit()\n",
    "# citation from MYSQL Connector.ipynb - (3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2.\n",
    "\n",
    "Create the table and Importing the data into table. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor = connection.cursor()\n",
    "createTableQuery = (\"\"\"CREATE TABLE IF NOT EXISTS `credit_record2` (\n",
    "  `ID` INT DEFAULT NULL,\n",
    "  `MONTHS_BALANCE` INT DEFAULT NULL,\n",
    "  `STATUS` text DEFAULT NULL\n",
    ") ENGINE=InnoDB;\"\"\")\n",
    "\n",
    "\n",
    "insertRowQuery=(\"\"\"INSERT INTO `credit_record2` (\n",
    "ID,MONTHS_BALANCE,STATUS)\n",
    "VALUES (%s, %s, %s)\"\"\")\n",
    "\n",
    "cursor.execute(createTableQuery)\n",
    "connection.commit()\n",
    "\n",
    "with open(\"credit_record.csv\") as file:\n",
    "    reader = csv.reader(file, delimiter=\",\")\n",
    "    \n",
    "    next(reader)\n",
    "    for row in reader:\n",
    "        cursor.execute(insertRowQuery, (row[0], row[1],row[2]))\n",
    "        \n",
    "connection.commit()\n",
    "        \n",
    "connection.close()\n",
    "# citation from MYSQL Connector.ipynb - (3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3. SQL\n",
    "\n",
    "SQL Queries 1.\n",
    "\n",
    "Cleanup and organization the dataset\n",
    "\n",
    "From the original dataset, each ID has different number of monthly balances, so I try to restructure the dataframe by groupby each ID. Before doing restructure, I need to check that each ID has different number of monthly balance or not?\n",
    "The reason why do that, if each ID has same number of monthly balance, I can restructure the dataframe by groupby() mean value of monthly balance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SELECT * FROM wonje_choi2.credit_record2;\n",
    "\n",
    "SELECT ID, COUNT(ID)\n",
    "FROM wonje_choi2.credit_record2\n",
    "GROUP BY ID;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SQL Queries 2.\n",
    "\n",
    "Once I confirmed that each ID has different number of ID by the SQL. Hence, I are going to do restructure the dataframe by gourpby each ID. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SELECT ID, MONTHS_BALANCE, STATUS\n",
    "FROM  wonje_choi2.credit_record2\n",
    "GROUP BY ID,MONTHS_BALANCE ;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SQL Queries 3.\n",
    "\n",
    "Each ID has different number of monthly balances, so it's hard to make a decision the client who is credit card company approval the applicants base on the monthly balance. All ID has a credit record from our dataset, so we think correcting the data which is the most recently monthly balance's status each ID after that using an inner or outer join between two datasets and various groupings, we will structure our data in SQL. It will help to client can make a decision the application of credit card."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SELECT ID, MAX(MONTHS_BALANCE), STATUS\n",
    "FROM  wonje_choi2.credit_record2\n",
    "GROUP BY ID;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SQL Queries 4.\n",
    "\n",
    "If applicants complain that it is unfair reject or approval by only last month of balances, so we should think other ways. \n",
    "In other way, we can drop the data that applicants who have any overdue or bad debts by their credit status. If applicants have any overdue or bad debts before, the client will reject their credit card application. \n",
    "Based on the dataset, starting from 2 is that overdue or bad debts at STATUS. For example, the value  of STATUS is over 1.5, applicants will be rejected their application. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SELECT ID, MONTHS_BALANCE, STATUS\n",
    "FROM wonje_choi2.credit_record2\n",
    "WHERE STATUS not like '2' and '3' and '4' and '5'\n",
    "GROUP BY ID;\n",
    "# citation from W3 Schools - (4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SQL Queries 5.\n",
    "\n",
    "Moreover, each ID has different number of monthly balances, so we can calculate the average of STATUS and we set up the criteria of average of STATUS. If applicants who have over our criteria of average of STATUS, applicants will get reject their credit card application. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SELECT ID, MONTHS_BALANCE, AVG(STATUS)\n",
    "FROM wonje_choi2.credit_record2 \n",
    "WHERE STATUS\n",
    "GROUP BY ID;\n",
    "# citation from W3 Schools - (5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I restructured the dataset are 3 ways that we will merge together with our other datasets to showing which ways are the best fit for our dataset.\n",
    "\n",
    "It is informative. The reason why, one of important the primary techniques of a data scientist is data wrangling. On the real-world problem, there has so many different types of ways to data wrangling at the same problem, so I tried to different ways of data wrangling for using an inner or outer join between two datasets and various groupings, we will structure our data in SQL. I learnt that whatever platform I finish up using the ability to think about what types of dataset I need and working on with that dataset is a highly relevant and data wrangling skill from this project.\n",
    "\n",
    "\n",
    "It's biased because this dataset is from kaggle.com and author is Seanny whose Student at University of Maryland in United States.\n",
    "From the website, 9 reviewers had the opportunity to review this material and the dataset got 10/10 Usability score which means that Easy to understand and includes essential data, Rich, machine readable file formats and data and Assurances the dataset is maintained. Also, most of 9 reviewers are Data Scientist or Data Science Students. Hence, I would like to say that I trust the reviewers, so it is rigorous.(1) \n",
    "\n",
    "There are indicators about whether the information is accurate. The author replied the someone's comments for asking data source. He mentioned that the dataset was originally from Chinese website. It has somebody else whose teacher of online data science course instruction in China written about this dataset by R Studio.(6) I think it is correct dataset. Also, there has some errors about understanding the monthly balances that shows negative values. Some of reviewers provided their own critique the monthly balances to understand the value of monthly balances. It is useful because I couldn’t understand why the monthly balances are negative value as well.\n",
    "\n",
    "Organizing our dataset to serve a particular need is another skill that is relevant both in python and SQL and across platforms. This inidividual milestone helps me apply that skill on a real-world problem. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference\n",
    "\n",
    "1.Seanny. (2020, March 24). Credit Card Approval Prediction. Kaggle. https://www.kaggle.com/rikdifos/credit-card-approval-prediction?select=credit_record.csv\n",
    "\n",
    "2.Seanny. (2020, March 24). Credit Card Approval Prediction. Kaggle. https://www.kaggle.com/rikdifos/credit-card-approval-prediction?select=application_record.csv\n",
    "\n",
    "3.Davies, C. (2021, November 15). MYSQL Connector. University of Calgary.\n",
    "https://d2l.ucalgary.ca/d2l/le/content/400972/viewContent/4998206/View\n",
    "\n",
    "4.SQL LIKE Operator. (n.d.). W3 Schools. Retrieved November 22, 2021, from https://www.w3schools.com/sql/sql_like.asp\n",
    "\n",
    "5.SQL COUNT(), AVG() and SUM() Functions. (n.d.). W3 Schools. Retrieved November 22, 2021, from https://www.w3schools.com/sql/sql_count_avg_sum.asp\n",
    "\n",
    "6.Xiong, X. (2019, October 22). 熊学堂 · 课程介绍 | 在线实习 之 《信用卡申请评分模型》. 微信公众平台. https://mp.weixin.qq.com/s/upjzuPg5AMIDsGxlpqnoCg\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
